#!/usr/bin/env python3
"""
æµ‹è¯•è¿è¡Œè„šæœ¬
æä¾›å®Œæ•´çš„æµ‹è¯•å¥—ä»¶æ‰§è¡Œå’ŒæŠ¥å‘Šç”Ÿæˆ
"""

import os
import sys
import subprocess
import argparse
import time
from pathlib import Path
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

class TestRunner:
    """æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self):
        self.project_root = project_root
        self.test_results = {}
        
    def run_unit_tests(self) -> Dict[str, Any]:
        """è¿è¡Œå•å…ƒæµ‹è¯•"""
        print("ğŸ§ª è¿è¡Œå•å…ƒæµ‹è¯•...")
        
        cmd = [
            "python", "-m", "pytest",
            "tests/unit/",
            "-v",
            "--tb=short",
            "--cov=app",
            "--cov-report=term-missing",
            "--cov-report=html:htmlcov",
            "--junit-xml=test-results/unit-tests.xml",
            "-m", "unit"
        ]
        
        start_time = time.time()
        result = subprocess.run(cmd, cwd=self.project_root, capture_output=True, text=True)
        duration = time.time() - start_time
        
        return {
            "name": "å•å…ƒæµ‹è¯•",
            "success": result.returncode == 0,
            "duration": duration,
            "output": result.stdout,
            "error": result.stderr
        }
    
    def run_integration_tests(self) -> Dict[str, Any]:
        """è¿è¡Œé›†æˆæµ‹è¯•"""
        print("ğŸ”— è¿è¡Œé›†æˆæµ‹è¯•...")
        
        cmd = [
            "python", "-m", "pytest",
            "tests/integration/",
            "-v",
            "--tb=short",
            "--junit-xml=test-results/integration-tests.xml",
            "-m", "integration"
        ]
        
        start_time = time.time()
        result = subprocess.run(cmd, cwd=self.project_root, capture_output=True, text=True)
        duration = time.time() - start_time
        
        return {
            "name": "é›†æˆæµ‹è¯•",
            "success": result.returncode == 0,
            "duration": duration,
            "output": result.stdout,
            "error": result.stderr
        }
    
    def run_e2e_tests(self) -> Dict[str, Any]:
        """è¿è¡Œç«¯åˆ°ç«¯æµ‹è¯•"""
        print("ğŸ¯ è¿è¡Œç«¯åˆ°ç«¯æµ‹è¯•...")
        
        cmd = [
            "python", "-m", "pytest",
            "tests/e2e/",
            "-v",
            "--tb=short",
            "--junit-xml=test-results/e2e-tests.xml",
            "-m", "e2e"
        ]
        
        start_time = time.time()
        result = subprocess.run(cmd, cwd=self.project_root, capture_output=True, text=True)
        duration = time.time() - start_time
        
        return {
            "name": "ç«¯åˆ°ç«¯æµ‹è¯•",
            "success": result.returncode == 0,
            "duration": duration,
            "output": result.stdout,
            "error": result.stderr
        }
    
    def run_performance_tests(self, users: int = 10, spawn_rate: int = 2, run_time: str = "60s") -> Dict[str, Any]:
        """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
        print("âš¡ è¿è¡Œæ€§èƒ½æµ‹è¯•...")
        
        # æ£€æŸ¥Locustæ˜¯å¦å®‰è£…
        try:
            subprocess.run(["locust", "--version"], check=True, capture_output=True)
        except (subprocess.CalledProcessError, FileNotFoundError):
            return {
                "name": "æ€§èƒ½æµ‹è¯•",
                "success": False,
                "duration": 0,
                "output": "",
                "error": "Locustæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install locust"
            }
        
        cmd = [
            "locust",
            "-f", "tests/performance/locustfile.py",
            "--host", "http://localhost:8000",
            "--users", str(users),
            "--spawn-rate", str(spawn_rate),
            "--run-time", run_time,
            "--headless",
            "--html", "test-results/performance-report.html"
        ]
        
        start_time = time.time()
        result = subprocess.run(cmd, cwd=self.project_root, capture_output=True, text=True)
        duration = time.time() - start_time
        
        return {
            "name": "æ€§èƒ½æµ‹è¯•",
            "success": result.returncode == 0,
            "duration": duration,
            "output": result.stdout,
            "error": result.stderr
        }
    
    def run_security_tests(self) -> Dict[str, Any]:
        """è¿è¡Œå®‰å…¨æµ‹è¯•"""
        print("ğŸ”’ è¿è¡Œå®‰å…¨æµ‹è¯•...")
        
        # ä½¿ç”¨banditè¿›è¡Œå®‰å…¨æ‰«æ
        cmd = [
            "python", "-m", "bandit",
            "-r", "app/",
            "-f", "json",
            "-o", "test-results/security-report.json"
        ]
        
        start_time = time.time()
        result = subprocess.run(cmd, cwd=self.project_root, capture_output=True, text=True)
        duration = time.time() - start_time
        
        # banditè¿”å›éé›¶çŠ¶æ€ç è¡¨ç¤ºå‘ç°é—®é¢˜ï¼Œä½†ä¸ä¸€å®šæ˜¯é”™è¯¯
        success = result.returncode in [0, 1]
        
        return {
            "name": "å®‰å…¨æµ‹è¯•",
            "success": success,
            "duration": duration,
            "output": result.stdout,
            "error": result.stderr if result.returncode > 1 else ""
        }
    
    def run_code_quality_tests(self) -> Dict[str, Any]:
        """è¿è¡Œä»£ç è´¨é‡æµ‹è¯•"""
        print("ğŸ“Š è¿è¡Œä»£ç è´¨é‡æµ‹è¯•...")
        
        results = []
        
        # Flake8 ä»£ç é£æ ¼æ£€æŸ¥
        flake8_cmd = ["python", "-m", "flake8", "app/", "--output-file=test-results/flake8-report.txt"]
        flake8_result = subprocess.run(flake8_cmd, cwd=self.project_root, capture_output=True, text=True)
        
        # MyPy ç±»å‹æ£€æŸ¥
        mypy_cmd = ["python", "-m", "mypy", "app/", "--ignore-missing-imports"]
        mypy_result = subprocess.run(mypy_cmd, cwd=self.project_root, capture_output=True, text=True)
        
        success = flake8_result.returncode == 0 and mypy_result.returncode == 0
        
        return {
            "name": "ä»£ç è´¨é‡æµ‹è¯•",
            "success": success,
            "duration": 0,
            "output": f"Flake8: {flake8_result.stdout}\nMyPy: {mypy_result.stdout}",
            "error": f"Flake8: {flake8_result.stderr}\nMyPy: {mypy_result.stderr}"
        }
    
    def setup_test_environment(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        print("ğŸ”§ è®¾ç½®æµ‹è¯•ç¯å¢ƒ...")
        
        # åˆ›å»ºæµ‹è¯•ç»“æœç›®å½•
        os.makedirs("test-results", exist_ok=True)
        
        # è®¾ç½®ç¯å¢ƒå˜é‡
        os.environ["TESTING"] = "1"
        os.environ["DATABASE_URL"] = "sqlite+aiosqlite:///./test.db"
        
        # å®‰è£…æµ‹è¯•ä¾èµ–
        subprocess.run([
            "pip", "install", "-e", ".",
            "pytest", "pytest-asyncio", "pytest-cov",
            "httpx", "bandit", "flake8", "mypy"
        ], check=True)
    
    def cleanup_test_environment(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        print("ğŸ§¹ æ¸…ç†æµ‹è¯•ç¯å¢ƒ...")
        
        # åˆ é™¤æµ‹è¯•æ•°æ®åº“
        test_db_files = ["test.db", "test.db-shm", "test.db-wal"]
        for file in test_db_files:
            if os.path.exists(file):
                os.remove(file)
    
    def generate_report(self, results: List[Dict[str, Any]]):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“‹ æµ‹è¯•æŠ¥å‘Š")
        print("="*60)
        
        total_duration = sum(r["duration"] for r in results)
        passed_tests = sum(1 for r in results if r["success"])
        total_tests = len(results)
        
        print(f"æ€»æµ‹è¯•å¥—ä»¶: {total_tests}")
        print(f"é€šè¿‡: {passed_tests}")
        print(f"å¤±è´¥: {total_tests - passed_tests}")
        print(f"æ€»è€—æ—¶: {total_duration:.2f}ç§’")
        print()
        
        for result in results:
            status = "âœ… é€šè¿‡" if result["success"] else "âŒ å¤±è´¥"
            print(f"{status} {result['name']} ({result['duration']:.2f}s)")
            
            if not result["success"] and result["error"]:
                print(f"   é”™è¯¯: {result['error'][:200]}...")
        
        print("\n" + "="*60)
        
        # ç”ŸæˆHTMLæŠ¥å‘Š
        self.generate_html_report(results)
    
    def generate_html_report(self, results: List[Dict[str, Any]]):
        """ç”ŸæˆHTMLæµ‹è¯•æŠ¥å‘Š"""
        html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>EmbedAI æµ‹è¯•æŠ¥å‘Š</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 20px; }}
                .header {{ background: #f0f0f0; padding: 20px; border-radius: 5px; }}
                .test-result {{ margin: 10px 0; padding: 15px; border-radius: 5px; }}
                .success {{ background: #d4edda; border: 1px solid #c3e6cb; }}
                .failure {{ background: #f8d7da; border: 1px solid #f5c6cb; }}
                .summary {{ display: flex; gap: 20px; margin: 20px 0; }}
                .metric {{ text-align: center; padding: 15px; background: #e9ecef; border-radius: 5px; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>EmbedAI ç³»ç»Ÿæµ‹è¯•æŠ¥å‘Š</h1>
                <p>ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}</p>
            </div>
            
            <div class="summary">
                <div class="metric">
                    <h3>{len(results)}</h3>
                    <p>æ€»æµ‹è¯•å¥—ä»¶</p>
                </div>
                <div class="metric">
                    <h3>{sum(1 for r in results if r['success'])}</h3>
                    <p>é€šè¿‡</p>
                </div>
                <div class="metric">
                    <h3>{sum(1 for r in results if not r['success'])}</h3>
                    <p>å¤±è´¥</p>
                </div>
                <div class="metric">
                    <h3>{sum(r['duration'] for r in results):.1f}s</h3>
                    <p>æ€»è€—æ—¶</p>
                </div>
            </div>
            
            <h2>è¯¦ç»†ç»“æœ</h2>
        """
        
        for result in results:
            status_class = "success" if result["success"] else "failure"
            status_text = "é€šè¿‡" if result["success"] else "å¤±è´¥"
            
            html_content += f"""
            <div class="test-result {status_class}">
                <h3>{result['name']} - {status_text} ({result['duration']:.2f}s)</h3>
                <details>
                    <summary>æŸ¥çœ‹è¯¦æƒ…</summary>
                    <pre>{result['output'][:1000]}...</pre>
                    {f'<p><strong>é”™è¯¯:</strong> {result["error"][:500]}...</p>' if result['error'] else ''}
                </details>
            </div>
            """
        
        html_content += """
        </body>
        </html>
        """
        
        with open("test-results/test-report.html", "w", encoding="utf-8") as f:
            f.write(html_content)
        
        print(f"ğŸ“„ HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: test-results/test-report.html")
    
    def run_all_tests(self, include_performance: bool = False, performance_config: Dict = None):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹å®Œæ•´ç³»ç»Ÿæµ‹è¯•...")
        
        # è®¾ç½®æµ‹è¯•ç¯å¢ƒ
        self.setup_test_environment()
        
        try:
            results = []
            
            # è¿è¡Œå„ç§æµ‹è¯•
            results.append(self.run_unit_tests())
            results.append(self.run_integration_tests())
            results.append(self.run_e2e_tests())
            results.append(self.run_security_tests())
            results.append(self.run_code_quality_tests())
            
            if include_performance:
                perf_config = performance_config or {}
                results.append(self.run_performance_tests(**perf_config))
            
            # ç”ŸæˆæŠ¥å‘Š
            self.generate_report(results)
            
            # è¿”å›æ€»ä½“ç»“æœ
            all_passed = all(r["success"] for r in results)
            return all_passed
            
        finally:
            # æ¸…ç†æµ‹è¯•ç¯å¢ƒ
            self.cleanup_test_environment()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="EmbedAI ç³»ç»Ÿæµ‹è¯•è¿è¡Œå™¨")
    parser.add_argument("--unit", action="store_true", help="åªè¿è¡Œå•å…ƒæµ‹è¯•")
    parser.add_argument("--integration", action="store_true", help="åªè¿è¡Œé›†æˆæµ‹è¯•")
    parser.add_argument("--e2e", action="store_true", help="åªè¿è¡Œç«¯åˆ°ç«¯æµ‹è¯•")
    parser.add_argument("--performance", action="store_true", help="åŒ…å«æ€§èƒ½æµ‹è¯•")
    parser.add_argument("--users", type=int, default=10, help="æ€§èƒ½æµ‹è¯•ç”¨æˆ·æ•°")
    parser.add_argument("--spawn-rate", type=int, default=2, help="æ€§èƒ½æµ‹è¯•ç”Ÿæˆé€Ÿç‡")
    parser.add_argument("--run-time", default="60s", help="æ€§èƒ½æµ‹è¯•è¿è¡Œæ—¶é—´")
    
    args = parser.parse_args()
    
    runner = TestRunner()
    
    if args.unit:
        result = runner.run_unit_tests()
        print(f"å•å…ƒæµ‹è¯•ç»“æœ: {'é€šè¿‡' if result['success'] else 'å¤±è´¥'}")
    elif args.integration:
        result = runner.run_integration_tests()
        print(f"é›†æˆæµ‹è¯•ç»“æœ: {'é€šè¿‡' if result['success'] else 'å¤±è´¥'}")
    elif args.e2e:
        result = runner.run_e2e_tests()
        print(f"ç«¯åˆ°ç«¯æµ‹è¯•ç»“æœ: {'é€šè¿‡' if result['success'] else 'å¤±è´¥'}")
    else:
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        performance_config = {
            "users": args.users,
            "spawn_rate": args.spawn_rate,
            "run_time": args.run_time
        } if args.performance else None
        
        success = runner.run_all_tests(
            include_performance=args.performance,
            performance_config=performance_config
        )
        
        exit_code = 0 if success else 1
        sys.exit(exit_code)


if __name__ == "__main__":
    main()
